{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings is a dataframe string 1.9 million word vectors length 300\n",
    "with pd.HDFStore('datascience.h5') as hdf:\n",
    "    embeddings = pd.read_hdf(hdf, key='embeddings')\n",
    "    pos_words = pd.read_hdf(hdf, key='pos_words')\n",
    "    neg_words = pd.read_hdf(hdf, key='neg_words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with senticnet dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentic_data = pd.read_csv('senticnet5.txt',sep='\\t', keep_default_na = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words2 = []\n",
    "targets_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RepresentsFloat(s):\n",
    "    try: \n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "for index, row in sentic_data.iterrows():\n",
    "    if '_' not in row['CONCEPT']:\n",
    "        words2.append(row['CONCEPT'])\n",
    "        for col in row:\n",
    "            if RepresentsInt(col):\n",
    "                targets_dict[row['CONCEPT']] = float(col)\n",
    "                break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors2 = embeddings.reindex(words2).dropna()\n",
    "labels2 = vectors2.index\n",
    "targets2 = []\n",
    "for label in labels2:\n",
    "    targets2.append(targets_dict[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors2, test_vectors2, train_targets2, test_targets2, train_labels2, test_labels2 = \\\n",
    "    train_test_split(vectors2, targets2, labels2, test_size=0.2, random_state=0)\n",
    "\n",
    "train_labels2 = list(train_labels2)\n",
    "test_labels2 = list(test_labels2)\n",
    "model2 = LinearRegression()\n",
    "model2.fit(train_vectors2, train_targets2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent(word):\n",
    "    vec = embeddings.loc[word].dropna()\n",
    "    return model2.predict([vec])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with UIC dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word = 'horrible'\n",
    "vec = embeddings.loc[word].dropna()\n",
    "model2.predict(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_vectors = embeddings.reindex(pos_words).dropna()\n",
    "neg_vectors = embeddings.reindex(neg_words).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = pd.concat([pos_vectors, neg_vectors])\n",
    "targets = np.array([1 for entry in pos_vectors.index] + [-1 for entry in neg_vectors.index])\n",
    "labels = list(pos_vectors.index) + list(neg_vectors.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors, test_vectors, train_targets, test_targets, train_labels, test_labels = \\\n",
    "    train_test_split(vectors, targets, labels, test_size=0.1, random_state=0)\n",
    "model = LogisticRegression()\n",
    "model.fit(train_vectors, train_targets)\n",
    "accuracy_score(model.predict(test_vectors), test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(model.predict(test_vectors2), test_targets2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(model2.predict(test_vectors), test_targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
